{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch \nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir('../input/digit-recognizer'))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:03:38.886036Z","iopub.execute_input":"2022-07-03T13:03:38.886533Z","iopub.status.idle":"2022-07-03T13:03:42.261947Z","shell.execute_reply.started":"2022-07-03T13:03:38.886434Z","shell.execute_reply":"2022-07-03T13:03:42.261026Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r'../input/digit-recognizer/train.csv', dtype=np.float32)\n\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:, train.columns != 'label'].values / 255\n\nfeatures_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size=0.2, \n                                                                             random_state=42)\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor)\n\nfeaturesTest = torch.from_numpy(features_test)\ntargetsTest = torch.from_numpy(targets_test).type(torch.LongTensor)\n\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\ntrain = torch.utils.data.TensorDataset(featuresTrain, targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest, targetsTest)\n\ntrain_loader = DataLoader(train, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test, batch_size=batch_size, shuffle=False)\n\nplt.imshow(features_numpy[0].reshape(28,28))\nplt.axis('off')\nplt.title(str(targets_numpy[0]))\nplt.savefig('graph.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:03:52.411652Z","iopub.execute_input":"2022-07-03T13:03:52.412241Z","iopub.status.idle":"2022-07-03T13:03:57.071474Z","shell.execute_reply.started":"2022-07-03T13:03:52.412208Z","shell.execute_reply":"2022-07-03T13:03:57.070145Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create CNN Model\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        # Convolution 1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # Max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n     \n        # Convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # Max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        \n        # Fully connected 1\n        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n    \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n\n        # Linear function (readout)\n        out = self.fc1(out)\n        \n        return out\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 2500\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\ntest = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n    \n# Create CNN\nmodel = CNNModel()\n\n# Cross Entropy Loss \nerror = nn.CrossEntropyLoss()\n\n# SGD Optimizer\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:07:45.118908Z","iopub.execute_input":"2022-07-03T13:07:45.119327Z","iopub.status.idle":"2022-07-03T13:07:45.141390Z","shell.execute_reply.started":"2022-07-03T13:07:45.119294Z","shell.execute_reply":"2022-07-03T13:07:45.140466Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"count = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        \n        train = Variable(images.view(100,1,28,28))\n        labels = Variable(labels)\n        \n        # Clear gradients\n        optimizer.zero_grad()\n        \n        # Forward propagation\n        outputs = model(train)\n        \n        # Calculate softmax and ross entropy loss\n        loss = error(outputs, labels)\n        \n        # Calculating gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        count += 1\n        \n        if count % 50 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in test_loader:\n                \n                test = Variable(images.view(100,1,28,28))\n                \n                # Forward propagation\n                outputs = model(test)\n                \n                # Get predictions from the maximum value\n                predicted = torch.max(outputs.data, 1)[1]\n                \n                # Total number of labels\n                total += len(labels)\n                \n                correct += (predicted == labels).sum()\n            \n            accuracy = 100 * correct / float(total)\n            \n            # store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        if count % 500 == 0:\n            # Print Loss\n            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T13:07:49.647825Z","iopub.execute_input":"2022-07-03T13:07:49.648230Z","iopub.status.idle":"2022-07-03T13:09:05.443041Z","shell.execute_reply.started":"2022-07-03T13:07:49.648198Z","shell.execute_reply":"2022-07-03T13:09:05.441471Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"CNN: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"CNN: Accuracy vs Number of iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T11:31:58.874361Z","iopub.execute_input":"2022-07-03T11:31:58.874778Z","iopub.status.idle":"2022-07-03T11:31:59.226516Z","shell.execute_reply.started":"2022-07-03T11:31:58.874746Z","shell.execute_reply":"2022-07-03T11:31:59.225373Z"},"trusted":true},"execution_count":36,"outputs":[]}]}